{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading:\n",
    "\n",
    "## Use Jupyter Lab alongside the marking_notebook.ipynb\n",
    "1. Open up this marking_notebook.ipynb in Jupyter Lab\n",
    "2. Make sure all the files you are marking are moved into this same folder as this `assignment6` folder.\n",
    "3. You can split your screen to this marking notebook on one side and student's .ipynb on the other side by side (see image). This can help to see where they went wrong if there are errors in the tests.\n",
    "4. Run the set-up cells, and iterate over the tests per notebook you are marking. It will go through the files alphabetically and clear the workspace for each student. \n",
    "\n",
    "![alt](./marking-setup.png)\n",
    "\n",
    "# Things that might come up\n",
    "### Marking in batches\n",
    "If you mark some assignments and want to come back and do the rest, remove those marked notebooks from the folder\n",
    "\n",
    "### Missing .py file\n",
    "This will only go through .py files that are submitted, if it's missing or they uploaded a zip file. You can save to the end to go through those individually.\n",
    "\n",
    "### Errors running .py file\n",
    "If the .py script does not execute. Take a look at the notebook. And you can copy the following test cells at the bottom of the student's notebook and run within their file.\n",
    "\n",
    "### NameError (students didn't name variables correctly)\n",
    "Students should be docked 0.25 marks if they do not use the variable names we asked for. \n",
    "\n",
    "**This is a one time deduction** (i.e. if they name things wrong for multiple questions, they do not lose more marks, just docked 0.25 for the whole assignment.)\n",
    "___\n",
    "\n",
    "Start here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "MARKED_DIR = Path(\"./marked/\")\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/BME1478H/Winter2020class/master/data/world-data-gapminder.csv'\n",
    " = pd.read_csv(url)\n",
    "\n",
    "fnames = glob('*.py*')\n",
    "fnames.sort()\n",
    "fnames_iter = iter(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renames column for co2_per_capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i -- 's/co2_emissions/co2_per_capita/g' ./*.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Iterate over student files\n",
    "\n",
    "Do not rerun previous cells, **unless you restarted the notebook.**\n",
    "\n",
    "**For each student, run all the cells starting from here to:**\n",
    "- move marked files to marked folder\n",
    "- clears the variables\n",
    "- iterates to the next student. \n",
    "- prints that students response to **Task 1 (c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f (^world|^europe|^density|^high|^both|^year|^answer)\n",
    "fname = next(fnames_iter)\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run -i {fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1a (0.25 marks)\n",
    "# world_subset = world_data [['country' , 'life_expectancy', 'co2_per_capita']]\n",
    "\n",
    "assert isinstance(world_subset, pd.DataFrame), \"world_subset is not a dataframe\"\n",
    "assert world_subset.shape == (39201, 3), \\\n",
    "        f\"world_subset shape is {world_subset.shape} should be 39201, 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1b (0.5 marks)\n",
    "# world_slice =  world_data.iloc[0:12,-3:]\n",
    "\n",
    "assert isinstance(world_slice, pd.DataFrame), \"world_slice is not a dataframe\"\n",
    "assert world_slice.shape == (12,3), \\\n",
    "    f\"world_slice shape is {world_slice.shape} but should be (12,3)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_slice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 1c (0.25 marks)\n",
    "assert isinstance(answer, str), \"task 1c answer variable is not a string\"\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1d (0.5 marks)\n",
    "# year_100_value = world_data.loc[100, 'year']\n",
    "\n",
    "assert isinstance(year_100_value, pd.DataFrame) or isinstance(int(year_100_value), int), \"year_100_value is not a number or dataframe containing one number\"\n",
    "try:\n",
    "    assert (year_100_value == 1900) or (year_100_value.values[0] == 1900),\\\n",
    "            f\"year_100_value is {year_100_value} but should be 1900\"\n",
    "except:\n",
    "    print(year_100_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_100_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1e (0.5 marks)\n",
    "# world_slice_2 = world_data.loc[5:10,'country':'income_group']\n",
    "\n",
    "assert isinstance(world_slice_2, pd.DataFrame), \"world_slice_2 is not a dataframe\"\n",
    "assert world_slice_2.index[0] == 5, \"Did not slice from starting point 5\"\n",
    "assert world_slice_2.index[-1] == 10, \"Did not end slice at label 10, slicing by .loc is inclusive to the end of the slice\"\n",
    "assert world_slice_2.columns[0] == 'country', \"Did not start column slice at country\" \n",
    "assert world_slice_2.columns[-1] == 'income_group', f\"Did not end column slice to income_group\" \n",
    "assert world_slice_2.equals(wd.loc[5:10,'country':'income_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_slice_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2a (0.5 marks)\n",
    "# year_2014 = world_data['year']==2014\n",
    "\n",
    "assert isinstance(year_2014, pd.Series), \"year_2014 is not a boolean array/Series\"\n",
    "assert year_2014.equals(wd['year']==2014), \"year_2014 may have been created using the wrong year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2b (0.5 marks)\n",
    "# year_2014_subset = world_data[year_2014]\n",
    "\n",
    "assert isinstance(year_2014_subset, pd.DataFrame), \"year_2014_subset is not a dataframe\"\n",
    "assert year_2014_subset.shape[0] == 179,\\\n",
    "f\"{year_2014_subset.shape[0]} rows but should be 179\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2014_subset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2c (0.5 marks)\n",
    "# both_criterion_subset =world_data[criterion_1 & criterion_2]\n",
    "\n",
    "assert both_criterion_subset.shape[0] == 73,\\\n",
    "f\"{both_criterion_subset.shape[0]} rows but should be 73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2d (0.5 marks)\n",
    "# high_income_health = world_data.loc[criterion_1 & criterion_2][column_subset]\n",
    "\n",
    "assert isinstance(high_income_health, pd.DataFrame), \"high_income_health is not a dataframe\"\n",
    "assert high_income_health.shape == (9,3), f\"high_income_health shape is {high_income_health.shape} should be (9,3)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_income_health.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2e (0.75 marks)\n",
    "# pop_density_bool = world_data['pop_density'] > 1000\n",
    "# co2_per_capita_bool = world_data['co2_per_capita'] > 20\n",
    "# density_or_co2 = world_data.loc[(pop_density_bool | co2_per_capita_bool), ['country', 'year', 'pop_density', 'co2_per_capita']]\n",
    "\n",
    "assert isinstance(density_or_co2, pd.DataFrame), \"density_or_co2 is not a DataFrame\"\n",
    "assert density_or_co2.shape == (447,4), f\"shape is {density_or_co2.shape} should be (447,4)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2f (0.25 marks)\n",
    "# world_data['pop_millions'] = world_data['population']/1000000\n",
    "\n",
    "assert len(world_data.columns) == 15, f\"{len(world_data.columns)} columns but should be 15\"\n",
    "assert 'pop_millions' in world_data, \"no column pop_millions in world_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a and b (1 mark)\n",
    "#europe_subset = world_data[world_data['region'] == 'Europe'] (0.25 marks)\n",
    "#european_pop_density = europe_subset.groupby('sub_region')['pop_density'].mean() (0.5 marks)\n",
    "#european_pop_density/european_pop_density['Northern Europe'] (0.25 marks)\n",
    "\n",
    "assert isinstance(europe_subset, pd.DataFrame), \"europe_subset is not a dataframe\"\n",
    "assert (europe_subset.region.unique()[0] == \"Europe\") or (europe_subset.shape[0] == 8541),\\\n",
    "\"Did not subset region by Europe\"\n",
    "assert len(european_pop_density) == 4, \"did not groupby subregion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe_subset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "european_pop_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this moves the current student files into the 'marked' subdirectory\n",
    "nb_name = glob(f\"{fname[:12]}*.ipynb\")[0] # get notebook name\n",
    "shutil.move(nb_name, MARKED_DIR / nb_name) # move notebook\n",
    "shutil.move(fname, MARKED_DIR / fname) # move the files into the `marked` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done - Post student grade on quercus\n",
    "Aggregate the marks and post on Quercus.   \n",
    "\n",
    "You can go back up and move on to the next student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
